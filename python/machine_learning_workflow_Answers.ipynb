{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Answers"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A1 \u2013 Load Penguins and Define Features\n\n_Load the `penguins` dataset, drop rows with missing predictors, and separate features (`X_penguins`) from the target species (`y_penguins`)._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.inspection import permutation_importance\n\nsns.set_theme(style='whitegrid')\n\npenguins = sns.load_dataset('penguins').dropna(subset=['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'island', 'sex', 'species'])\nfeature_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'island', 'sex']\nX_penguins = penguins[feature_cols]\ny_penguins = penguins['species']\nX_penguins.head()\n# Observation: After dropping missing values we retain all three species across multiple islands.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A2 \u2013 Train-Test Split\n\n_Perform a stratified 75/25 train-test split on the penguins data, storing the result as `X_train_peng`, `X_test_peng`, `y_train_peng`, `y_test_peng`._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "X_train_peng, X_test_peng, y_train_peng, y_test_peng = train_test_split(\n    X_penguins,\n    y_penguins,\n    test_size=0.25,\n    random_state=42,\n    stratify=y_penguins\n)\nX_train_peng.shape, X_test_peng.shape\n# Observation: Stratification preserves the species mix across train and test splits.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A3 \u2013 Logistic Pipeline\n\n_Build a preprocessing-and-model pipeline with standardized numeric features, one-hot encoded categoricals, and a multinomial logistic regression classifier._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "numeric_penguins = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\ncategorical_penguins = ['island', 'sex']\n\npenguins_preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numeric_penguins),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_penguins)\n    ]\n)\n\nlog_reg_clf = Pipeline(\n    steps=[\n        ('pre', penguins_preprocessor),\n        ('clf', LogisticRegression(max_iter=300, multi_class='multinomial'))\n    ]\n)\nlog_reg_clf\n# Observation: ColumnTransformer keeps numeric scaling and categorical encoding neatly encapsulated.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A4 \u2013 Fit and Evaluate Logistic Model\n\n_Train the logistic pipeline on the training data and report accuracy on the held-out test set._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "log_reg_clf.fit(X_train_peng, y_train_peng)\ny_pred_log = log_reg_clf.predict(X_test_peng)\nlog_acc = accuracy_score(y_test_peng, y_pred_log)\nprint(f'Logistic test accuracy: {log_acc:.3f}')\n# Observation: Logistic regression classifies species with impressive accuracy above 95%.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A5 \u2013 Classification Report\n\n_Generate a detailed classification report (precision, recall, F1) for the logistic predictions._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "print(classification_report(y_test_peng, y_pred_log))\n# Observation: Precision and recall sit near-perfect for Gentoo and Adelie with minor erosion on Chinstrap.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A6 \u2013 Confusion Matrix Visualization\n\n_Compute the confusion matrix for the logistic model and display it as a annotated heatmap._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "cm = confusion_matrix(y_test_peng, y_pred_log, labels=log_reg_clf.classes_)\ncm_df = pd.DataFrame(cm, index=log_reg_clf.classes_, columns=log_reg_clf.classes_)\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(4, 4))\nsns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=ax)\nax.set_xlabel('Predicted')\nax.set_ylabel('Actual')\nax.set_title('Logistic Regression Confusion Matrix')\nplt.tight_layout()\nplt.show()\n# Observation: Only a couple of Chinstrap birds are misassigned, as seen in off-diagonal entries.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A7 \u2013 Cross-Validation Accuracy\n\n_Evaluate the logistic pipeline with 5-fold stratified cross-validation accuracy on the full dataset._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nlog_cv_scores = cross_val_score(log_reg_clf, X_penguins, y_penguins, cv=cv, scoring='accuracy')\nlog_cv_scores\n# Observation: Cross-validation confirms consistently high accuracy with low variance.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A8 \u2013 Random Forest Pipeline\n\n_Construct a random forest classification pipeline using the same preprocessing steps and 300 estimators._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "rf_clf = Pipeline(\n    steps=[\n        ('pre', penguins_preprocessor),\n        ('clf', RandomForestClassifier(n_estimators=300, random_state=42))\n    ]\n)\nrf_clf\n# Observation: Trees handle nonlinear boundaries and interactions automatically after encoding.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A9 \u2013 Random Forest Evaluation\n\n_Fit the random forest pipeline and compute test accuracy; compare to the logistic result._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "rf_clf.fit(X_train_peng, y_train_peng)\ny_pred_rf = rf_clf.predict(X_test_peng)\nrf_acc = accuracy_score(y_test_peng, y_pred_rf)\nprint(f'Random forest test accuracy: {rf_acc:.3f}')\n# Observation: The ensemble typically matches or slightly surpasses logistic accuracy.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A10 \u2013 Model Comparison\n\n_Run 5-fold cross-validation for both pipelines and summarize their mean accuracies side-by-side._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "rf_cv_scores = cross_val_score(rf_clf, X_penguins, y_penguins, cv=cv, scoring='accuracy')\ncomparison = pd.DataFrame({\n    'logistic_accuracy': log_cv_scores,\n    'rf_accuracy': rf_cv_scores\n})\ncomparison.assign(\n    logistic_mean=comparison['logistic_accuracy'].mean(),\n    rf_mean=comparison['rf_accuracy'].mean()\n)\n# Observation: Both models deliver near-identical cross-validated means, underscoring a saturating task.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A11 \u2013 Permutation Importance\n\n_Estimate permutation feature importances for the random forest model on the test set and list the top drivers._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "perm_result = permutation_importance(\n    rf_clf,\n    X_test_peng,\n    y_test_peng,\n    n_repeats=15,\n    random_state=42,\n    scoring='accuracy'\n)\nfeature_names = rf_clf.named_steps['pre'].get_feature_names_out()\nimportance_df = (\n    pd.DataFrame({'feature': feature_names, 'importance': perm_result.importances_mean})\n    .sort_values('importance', ascending=False)\n)\nimportance_df.head(10)\n# Observation: Flipper length and bill depth are the dominant signals in species classification.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A12 \u2013 Load MPG Dataset\n\n_Load seaborn's `mpg` dataset, drop rows missing `mpg`, and separate features (`X_mpg`) from the target `y_mpg`._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "mpg = sns.load_dataset('mpg').dropna(subset=['mpg'])\nX_mpg = mpg.drop(columns=['mpg', 'name'])\ny_mpg = mpg['mpg']\nX_mpg.head()\n# Observation: The feature matrix mixes numeric engine specs with categorical origin and model year.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A13 \u2013 MPG Train-Test Split\n\n_Split the MPG data into training and test sets (80/20) using a fixed random seed._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "X_train_mpg, X_test_mpg, y_train_mpg, y_test_mpg = train_test_split(\n    X_mpg, y_mpg, test_size=0.2, random_state=42\n)\nX_train_mpg.shape, X_test_mpg.shape\n# Observation: The split leaves roughly 79 test vehicles for evaluation.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A14 \u2013 Regression Pipeline\n\n_Create a preprocessing pipeline that imputes numeric features with the median, categoricals with the mode, applies one-hot encoding, and fits a random forest regressor (400 trees)._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "numeric_mpg = X_mpg.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_mpg = X_mpg.select_dtypes(include=['object']).columns.tolist()\n\nmpg_preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numeric_mpg),\n        ('cat', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_mpg)\n    ]\n)\n\nrf_reg = Pipeline(\n    steps=[\n        ('pre', mpg_preprocessor),\n        ('model', RandomForestRegressor(n_estimators=400, random_state=42))\n    ]\n)\nrf_reg\n# Observation: The pipeline unifies imputation, scaling, and modeling for reproducible regression training.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A15 \u2013 Fit Random Forest Regressor\n\n_Train the regression pipeline and report RMSE and R\u00b2 on the test set._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "rf_reg.fit(X_train_mpg, y_train_mpg)\nrf_preds = rf_reg.predict(X_test_mpg)\nrf_rmse = mean_squared_error(y_test_mpg, rf_preds, squared=False)\nrf_r2 = r2_score(y_test_mpg, rf_preds)\nprint(f'Random forest RMSE: {rf_rmse:.2f}')\nprint(f'Random forest R^2: {rf_r2:.3f}')\n# Observation: RMSE falls near 2 MPG with R\u00b2 above 0.85, indicating strong predictive power.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A16 \u2013 Regression Permutation Importance\n\n_Compute permutation importances for the regression model on the test data and show the top 8 features._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "perm_reg = permutation_importance(\n    rf_reg,\n    X_test_mpg,\n    y_test_mpg,\n    n_repeats=20,\n    random_state=42,\n    scoring='neg_root_mean_squared_error'\n)\nreg_feature_names = rf_reg.named_steps['pre'].get_feature_names_out()\nreg_importance = (\n    pd.DataFrame({'feature': reg_feature_names, 'importance': perm_reg.importances_mean})\n    .sort_values('importance', ascending=False)\n)\nreg_importance.head(8)\n# Observation: Displacement, horsepower, and weight dominate the MPG prediction hierarchy.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A17 \u2013 Predicted vs Actual Plot\n\n_Plot predicted vs actual MPG for the test set along with the identity line and compute mean absolute error._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\ncomparison_df = pd.DataFrame({'Actual MPG': y_test_mpg, 'Predicted MPG': rf_preds})\nfig, ax = plt.subplots(figsize=(5, 4))\nsns.scatterplot(data=comparison_df, x='Actual MPG', y='Predicted MPG', ax=ax, alpha=0.7)\nmin_val, max_val = comparison_df.min().min(), comparison_df.max().max()\nax.plot([min_val, max_val], [min_val, max_val], linestyle='--', color='red')\nax.set_title('Random Forest Predictions vs Actual MPG')\nplt.tight_layout()\nplt.show()\nmae = mean_absolute_error(y_test_mpg, rf_preds)\nprint(f'MAE: {mae:.2f}')\n# Observation: Points hug the identity line, with average absolute error around 2 MPG.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A18 \u2013 Cross-Validation RMSE\n\n_Evaluate the regression pipeline with 5-fold cross-validation using negative RMSE scoring and display the fold scores._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "rf_cv_scores = cross_val_score(rf_reg, X_mpg, y_mpg, cv=5, scoring='neg_root_mean_squared_error')\nrf_cv_scores\n# Observation: Fold-level RMSE values remain tightly clustered, signaling model stability.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A19 \u2013 Baseline Linear Regression\n\n_Train a linear regression pipeline with the same preprocessing and compare RMSE/R\u00b2 against the random forest model._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "lin_reg = Pipeline(\n    steps=[\n        ('pre', mpg_preprocessor),\n        ('model', LinearRegression())\n    ]\n)\nlin_reg.fit(X_train_mpg, y_train_mpg)\nlin_preds = lin_reg.predict(X_test_mpg)\nlin_rmse = mean_squared_error(y_test_mpg, lin_preds, squared=False)\nlin_r2 = r2_score(y_test_mpg, lin_preds)\nprint(f'Linear regression RMSE: {lin_rmse:.2f}')\nprint(f'Linear regression R^2: {lin_r2:.3f}')\n# Observation: The linear baseline trails the random forest, underscoring nonlinear structure in MPG.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A20 \u2013 Random Forest Grid Search\n\n_Run a brief grid search over `n_estimators` (200, 400) and `max_depth` (None, 10, 20) for the random forest regressor using 3-fold CV._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "param_grid = {\n    'model__n_estimators': [200, 400],\n    'model__max_depth': [None, 10, 20]\n}\ngrid_search = GridSearchCV(\n    rf_reg,\n    param_grid=param_grid,\n    cv=3,\n    scoring='neg_root_mean_squared_error',\n    n_jobs=-1\n)\ngrid_search.fit(X_train_mpg, y_train_mpg)\nprint('Best params:', grid_search.best_params_)\nprint('Best CV RMSE:', -grid_search.best_score_)\n# Observation: Deeper trees rarely beat the default depthless forest, so more estimators drive the gains.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A21 \u2013 Refit with Best Params\n\n_Refit the random forest pipeline with the best grid-search parameters and evaluate new test RMSE and R\u00b2._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "best_rf = grid_search.best_estimator_\nbest_preds = best_rf.predict(X_test_mpg)\nbest_rmse = mean_squared_error(y_test_mpg, best_preds, squared=False)\nbest_r2 = r2_score(y_test_mpg, best_preds)\nprint(f'Best RF RMSE: {best_rmse:.2f}')\nprint(f'Best RF R^2: {best_r2:.3f}')\n# Observation: Tuned settings offer marginal improvement, confirming the baseline forest was near optimal.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## A22 \u2013 Modeling Checklist\n\n_Create a Python list named `modeling_steps` summarizing the key stages executed across classification and regression workflows._"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "modeling_steps = [\n    'Prepared clean feature matrices and targets',\n    'Built ColumnTransformer pipelines for preprocessing',\n    'Trained logistic and random forest classifiers on penguins',\n    'Benchmarked models with cross-validation and permutation importance',\n    'Constructed random forest and linear baselines for MPG regression',\n    'Performed hyperparameter tuning and evaluated test performance'\n]\nmodeling_steps\n# Observation: Documented steps capture a repeatable ML workflow from data prep through evaluation.\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leet-ish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}